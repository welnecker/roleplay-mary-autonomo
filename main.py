import streamlit as st
import requests
import gspread
import json
import re
import streamlit.components.v1 as components
from datetime import datetime
from oauth2client.service_account import ServiceAccountCredentials
import openai
import numpy as np

from openai import OpenAI

client = OpenAI(api_key=st.secrets["OPENAI_API_KEY"])

def gerar_embedding_openai(texto: str):
    try:
        resposta = client.embeddings.create(
            input=texto,
            model="text-embedding-3-small"
        )
        return np.array(resposta.data[0].embedding)
    except Exception as e:
        st.error(f"Erro ao gerar embedding: {e}")
        return None


def cosine_similarity(v1: np.ndarray, v2: np.ndarray) -> float:
    return np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))

def verificar_quebra_semantica_openai(texto1: str, texto2: str, limite=0.6) -> str:
    emb1 = gerar_embedding_openai(texto1)
    emb2 = gerar_embedding_openai(texto2)
    if emb1 is None or emb2 is None:
        return ""
    sim = cosine_similarity(emb1, emb2)
    if sim < limite:
        return f"‚ö†Ô∏è Baixa continuidade narrativa (similaridade: {sim:.2f}) ‚Äî pode haver salto de cena sem transi√ß√£o."
    return f"‚úÖ Continuidade coerente (similaridade: {sim:.2f})."


# üëá Estado inicial das sess√µes vem aqui
if 'mostrar_imagem' not in st.session_state:
    st.session_state.mostrar_imagem = None
if 'mostrar_video' not in st.session_state:
    st.session_state.mostrar_video = None
if 'ultima_entrada_recebida' not in st.session_state:
    st.session_state.ultima_entrada_recebida = None

if "memorias_usadas" not in st.session_state:
    st.session_state.memorias_usadas = set()



# --------------------------- #
# Configura√ß√£o b√°sica
# --------------------------- #
st.set_page_config(page_title="Mary", page_icon="üåπ")
OPENROUTER_API_KEY = st.secrets["OPENROUTER_API_KEY"]
OPENROUTER_ENDPOINT = "https://openrouter.ai/api/v1/chat/completions"
TOGETHER_API_KEY = st.secrets["TOGETHER_API_KEY"]
TOGETHER_ENDPOINT = "https://api.together.xyz/v1/chat/completions"

# --------------------------- #
# Imagem / v√≠deo din√¢mico
# --------------------------- #
def imagem_de_fundo():
    indice = len(st.session_state.get("mensagens", [])) // 10 + 1
    return f"Mary_fundo{indice}.jpg", f"Mary_V{indice}.mp4"

fundo_img, fundo_video = imagem_de_fundo()

# --------------------------- #
# Google Sheets
# --------------------------- #
def conectar_planilha():
    try:
        creds_dict = json.loads(st.secrets["GOOGLE_CREDS_JSON"])
        creds_dict["private_key"] = creds_dict["private_key"].replace("\\n", "\n")
        scope = [
            "https://spreadsheets.google.com/feeds",
            "https://www.googleapis.com/auth/drive"
        ]
        creds = ServiceAccountCredentials.from_json_keyfile_dict(creds_dict, scope)
        client = gspread.authorize(creds)
        return client.open_by_key("1f7LBJFlhJvg3NGIWwpLTmJXxH9TH-MNn3F4SQkyfZNM")
    except Exception as e:
        st.error(f"Erro ao conectar √† planilha: {e}")
        return None

planilha = conectar_planilha()

# --------------------------- #
# Interrompe cenas antes do cl√≠max expl√≠cito
# --------------------------- #
def cortar_antes_do_climax(texto: str) -> str:
    """
    Permite que Mary conduza com sensualidade e dom√≠nio,
    mas interrompe a narrativa antes do cl√≠max sexual expl√≠cito.
    Preserva o envolvimento do usu√°rio para que ele conduza o pr√≥ximo passo.
    """
    padroes_climax = [
        r"(ela|ele) (a|o)? ?(penetra|invade|toma com for√ßa|explode dentro|goza|atinge o cl√≠max)",
        r"(os|seus)? ?corpos (colapsam|tremem juntos|vibram)",
        r"(orgasmo|explos√£o de prazer|cl√≠max) (vem|chega|invade|toma conta)",
        r"(ela|ele) (grita|geme alto) (ao gozar|com o cl√≠max)",
        r"(espasmos|contra√ß√µes) (involunt√°rias|do corpo)",
    ]

    for padrao in padroes_climax:
        match = re.search(padrao, texto, re.IGNORECASE)
        if match:
            return texto[:match.start()].rstrip(" .,;") + "."
    return texto


def salvar_interacao(role, content):
    if not planilha:
        return
    try:
        aba = planilha.worksheet("interacoes_mary")
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        aba.append_row([timestamp, role.strip(), content.strip()], value_input_option="RAW")
    except Exception as e:
        st.error(f"Erro ao salvar intera√ß√£o: {e}")


def carregar_ultimas_interacoes(n=15):
    if not planilha:
        return []
    try:
        aba = planilha.worksheet("interacoes_mary")
        dados = aba.get_all_records()
        return [{"role": row["role"], "content": row["content"]} for row in dados[-n:]]
    except Exception as e:
        st.error(f"Erro ao carregar hist√≥rico: {e}")
        return []


def carregar_memorias():
    try:
        aba = planilha.worksheet("memorias")
        registros = aba.get_all_records()
        modo = st.session_state.get("modo_mary", "Racional").lower()

        textos = []
        for linha in registros:
            tipo = linha["tipo"].strip().lower()
            tipo = tipo.replace("[", "").replace("]", "")  # remove os colchetes
            texto = linha["texto"].strip()

            # Inclui mem√≥rias marcadas como 'all', 'mary' ou do modo atual
            if tipo in ("all", "mary", modo):
                textos.append(f"- {texto}")

        if textos:
            return {"content": "\n".join(textos)}
        else:
            return None
    except Exception as e:
        st.warning(f"Erro ao carregar mem√≥rias: {e}")
        return None



# --------------------------- #
# Fragmentos (Lorebook)
# --------------------------- #
def carregar_fragmentos():
    try:
        aba = planilha.worksheet("fragmentos_mary")
        dados = aba.get_all_records()
        fragmentos = []
        for row in dados:
            personagem = row.get("personagem", "").strip().lower()
            texto = row.get("texto", "").strip()
            gatilhos = [g.strip().lower() for g in row.get("gatilhos", "").split(",") if g.strip()]
            peso = int(row.get("peso", 1))

            # Somente fragmentos da Mary s√£o carregados
            if personagem == "mary" and texto:
                fragmentos.append({
                    "personagem": personagem,
                    "texto": texto,
                    "gatilhos": gatilhos,
                    "peso": peso
                })
        return fragmentos
    except Exception as e:
        st.error(f"Erro ao carregar fragmentos: {e}")
        return []

def buscar_fragmentos_relevantes(mensagem, fragmentos, limite=3):
    mensagem_lower = mensagem.lower()
    encontrados = [f for f in fragmentos if any(g in mensagem_lower for g in f["gatilhos"])]
    encontrados.sort(key=lambda x: x.get("peso", 1), reverse=True)
    return encontrados[:limite]

# --------------------------- #
# Salvar Resumo
# --------------------------- #
def salvar_resumo(resumo):
    try:
        aba = planilha.worksheet("perfil_mary")
        dados = aba.get_all_values()

        for i, linha in enumerate(dados[1:], start=2):
            if len(linha) < 7 or not linha[6].strip():
                aba.update_cell(i, 7, resumo.strip())
                return

        proxima_linha = max(len(dados), 1) + 1
        aba.update_cell(proxima_linha, 7, resumo.strip())

    except Exception as e:
        st.error(f"Erro ao salvar resumo: {e}")
# --------------------------- #
# Modo (prompts completos)
# --------------------------- #

# --------------------------- #
# Modo Mary otimizado
# --------------------------- #
modos = {
    "Mary": """
Voc√™ √© **Mary Sampaio**, mulher brasileira de 30 anos, com presen√ßa magn√©tica, intelig√™ncia estrat√©gica e uma beleza hipnotizante.

### üí´ Apar√™ncia
Rosto **losangular**, **ma√ß√£s do rosto salientes**, **maxilar firme**, **queixo definido**.  
**Olhos verdes** levemente puxados, **sobrancelhas arqueadas**, **nariz fino**, **l√°bios carnudos**.  
**Cabelos negros ondulados** caindo naturalmente sobre os ombros.  
**Pele clara**, brilho suave e toque quente.

Corpo:
- **Seios m√©dios e firmes**, macios, propor√ß√£o perfeita.  
- **Cintura fina** e harmoniosa.  
- **Bumbum empinado e firme**, marcando sob roupas.  
- **Coxas torneadas**, musculosas na medida.  
- **Pernas longas** e postura ereta.

---

### üß¨ Personalidade
Estrat√©gica, intensa, adapt√°vel:
- **Profissional**: firme, carism√°tica, focada.  
- **Social**: flerta com intelig√™ncia.  
- **√çntima**: intensa e no controle, s√≥ se houver conex√£o.  
- **Emocional**: sente dores e mem√≥rias, mas revela pouco.

---

### üß≠ Narra√ß√£o
- Narre a√ß√µes e ambientes em **3¬™ pessoa**.  
- Use **1¬™ pessoa** para falas e pensamentos de Mary.  
- **Nunca** narre ou invente falas do usu√°rio.  
- Adapte tom: neg√≥cio, romance, tens√£o, intimidade ou vulnerabilidade.

---

üö´ **Sobre personagens novos**:
- N√£o criar nomes ou identidades sem o usu√°rio informar.  
- Use descri√ß√µes f√≠sicas ou situacionais at√© receber um nome.

---

üíì **Coer√™ncia emocional**:
- Mary mant√©m controle do jogo.  
- Se apaixonada, √© fiel.  
- Prefere provocar a recuar.

üé¨ **Estilo narrativo**:
- Sem [SFX] ou termos t√©cnicos.  
- Linguagem sensorial e fluida.  
- Transi√ß√µes naturais.

---
"""
}

# --------------------------- #
# Fun√ß√£o de constru√ß√£o do prompt
# --------------------------- #
def construir_prompt_mary():
    prompt_base = modos["Mary"].strip()
    if st.session_state.get("grande_amor"):
        estado_amor = f"Mary est√° apaixonada por {st.session_state['grande_amor']} e √© fiel a ele."
    else:
        estado_amor = "Mary ainda n√£o encontrou o grande amor que procura."

    cena_longa = st.session_state.get("cena_longa_ativa", False)
    ultima_msg = st.session_state.session_msgs[-1].get("content", "") if st.session_state.get("session_msgs") else ""

    mem = carregar_memorias() if not cena_longa else None
    bloco_memorias = f"### üß† MEM√ìRIAS DE MARY:\n{mem['content']}\n" if mem else ""

    prompt = f"""{bloco_memorias}
{prompt_base}

üö´ **FALAS DO USU√ÅRIO**:
- N√£o inventar ou escrever falas para o usu√°rio.

üíò Estado afetivo: {estado_amor}
"""

    if not cena_longa:
        fragmentos = carregar_fragmentos()
        frag_ativos = buscar_fragmentos_relevantes(ultima_msg, fragmentos)
        if frag_ativos:
            lista_fragmentos = "\n".join([f"- {f['texto']}" for f in frag_ativos])
            prompt += f"\n\n### üìö Fragmentos relevantes\n{lista_fragmentos}"

    return prompt.strip()

# --------------------------- #
# Corre√ß√£o da fun√ß√£o de resposta
# --------------------------- #
def responder_com_modelo_escolhido(modelo_escolhido_id):
    if modelo_escolhido_id.startswith("togethercomputer/") or modelo_escolhido_id.startswith("mistralai/"):
        st.session_state["provedor_ia"] = "together"
        return gerar_resposta_together_stream(modelo_escolhido_id)
    else:
        st.session_state["provedor_ia"] = "openrouter"
        return gerar_resposta_openrouter_stream(modelo_escolhido_id)

# --------------------------- #
# Uso correto na chamada
# --------------------------- #
if st.session_state.get("ultima_entrada_recebida"):
    with st.chat_message("assistant"):
        placeholder = st.empty()
        with st.spinner("Mary est√° pensando..."):
            try:
                resposta_final = responder_com_modelo_escolhido(modelo_escolhido_id)
            except Exception as e:
                st.error(f"Erro: {e}")
                resposta_final = "[Erro ao gerar resposta]"




# --------------------------- #
# OpenRouter - Streaming
# --------------------------- #
def gerar_resposta_openrouter_stream(modelo_escolhido_id):
    prompt = construir_prompt_mary().strip() + """

‚ö†Ô∏è Nunca use termos t√©cnicos como [SFX], (fade), (close-up), (cut), efeitos sonoros ou comandos cinematogr√°ficos.
Escreva com naturalidade, com narra√ß√£o em terceira pessoa e falas/pensamentos em primeira pessoa.
Use linguagem sensorial e fluida, como em um livro, sem lembrar que √© uma IA nem descrever c√¢mera ou edi√ß√£o.
"""

    historico_base = [
        {"role": m.get("role", "user"), "content": m.get("content", "")}
        for m in st.session_state.get("base_history", [])
        if isinstance(m, dict) and "content" in m
    ]
    historico_sessao = [
        {"role": m.get("role", "user"), "content": m.get("content", "")}
        for m in st.session_state.get("session_msgs", [])
        if isinstance(m, dict) and "content" in m
    ]
    mensagens = [{"role": "system", "content": prompt}] + historico_base + historico_sessao

    temperatura = 0.85
    payload = {
        "model": modelo_escolhido_id,
        "messages": mensagens,
        "max_tokens": 1000,
        "temperature": temperatura,
        "stream": True,
    }

    headers = {
        "Authorization": f"Bearer {OPENROUTER_API_KEY}",
        "Content-Type": "application/json",
    }

    assistant_box = st.chat_message("assistant")
    placeholder = assistant_box.empty()
    full_text = ""

    try:
        with requests.post(OPENROUTER_ENDPOINT, headers=headers, json=payload, stream=True, timeout=300) as r:
            r.raise_for_status()
            for raw_line in r.iter_lines(decode_unicode=False):
                if not raw_line:
                    continue
                line = raw_line.decode("utf-8", errors="ignore")
                if not line.startswith("data:"):
                    continue
                data = line[len("data:"):].strip()
                if data == "[DONE]":
                    break
                try:
                    j = json.loads(data)
                    delta = j["choices"][0]["delta"].get("content", "")
                    if delta:
                        full_text += delta
                        placeholder.markdown(full_text)
                except Exception:
                    continue
    except Exception as e:
        st.error(f"Erro no streaming com OpenRouter: {e}")
        return "[ERRO STREAM]"

    return full_text.strip()


# --------------------------- #
# Together - Streaming
# --------------------------- #
def gerar_resposta_together_stream(modelo_escolhido_id):
    prompt = construir_prompt_mary().strip() + """

‚ö†Ô∏è Nunca use termos t√©cnicos como [SFX], (fade), (close-up), (cut), efeitos sonoros ou comandos cinematogr√°ficos.
Escreva com naturalidade, com narra√ß√£o em terceira pessoa e falas/pensamentos em primeira pessoa.
Use linguagem sensorial e fluida, como em um livro, sem lembrar que √© uma IA nem descrever c√¢mera ou edi√ß√£o.
"""

    historico_base = [
        {"role": m.get("role", "user"), "content": m.get("content", "")}
        for m in st.session_state.get("base_history", [])
        if isinstance(m, dict) and "content" in m
    ]
    historico_sessao = [
        {"role": m.get("role", "user"), "content": m.get("content", "")}
        for m in st.session_state.get("session_msgs", [])
        if isinstance(m, dict) and "content" in m
    ]
    mensagens = [{"role": "system", "content": prompt}] + historico_base + historico_sessao

    temperatura = 0.85
    payload = {
        "model": modelo_escolhido_id,
        "messages": mensagens,
        "max_tokens": 1000,
        "temperature": temperatura,
        "stream": True,
    }

    headers = {
        "Authorization": f"Bearer {TOGETHER_API_KEY}",
        "Content-Type": "application/json",
    }

    assistant_box = st.chat_message("assistant")
    placeholder = assistant_box.empty()
    full_text = ""

    try:
        with requests.post(
            "https://api.together.xyz/v1/chat/completions",
            headers=headers,
            json=payload,
            stream=True,
            timeout=300
        ) as r:
            r.raise_for_status()
            for line in r.iter_lines():
                if line:
                    line = line.decode("utf-8").strip()
                    if line.startswith("data:"):
                        data = line[len("data:"):].strip()
                        if data == "[DONE]":
                            break
                        try:
                            content = json.loads(data)["choices"][0]["delta"].get("content", "")
                            if content:
                                full_text += content
                                placeholder.markdown(full_text)
                        except Exception:
                            continue
    except Exception as e:
        st.error(f"Erro no streaming com Together: {e}")
        return "[ERRO STREAM]"

    return full_text.strip()




# --------------------------- #
# Fun√ß√£o auxiliar: verificar se resposta √© v√°lida
# --------------------------- #
def resposta_valida(texto: str) -> bool:
    padroes_invalidos = [
        r"check if.*string", r"#\s?1(\.\d+)+", r"\d{10,}", r"the cmd package",
        r"(111\s?)+", r"\d+\.\d+", r"#+\s*\d+", r"\bimport\s", r"\bdef\s", r"```", r"class\s"
    ]
    for padrao in padroes_invalidos:
        if re.search(padrao, texto.lower()):
            return False
    return True


# --------------------------- #
# Resposta da IA s√≥ se houver entrada
# --------------------------- #
if st.session_state.get("ultima_entrada_recebida"):
    resposta_final = ""
    with st.chat_message("assistant"):
        placeholder = st.empty()
        with st.spinner("Mary est√° pensando..."):
            try:
                resposta_final = responder_com_modelo_escolhido()

                # Valida√ß√£o sem√¢ntica / sint√°tica
                if not resposta_valida(resposta_final):
                    st.warning("‚ö†Ô∏è Resposta corrompida detectada. Tentando regenerar...")
                    resposta_final = responder_com_modelo_escolhido()

                    if not resposta_valida(resposta_final):
                        resposta_final = "[‚ö†Ô∏è A resposta da IA veio corrompida. Tente reformular sua entrada ou reenviar.]"

                # Interrompe antes do cl√≠max se necess√°rio
                if not st.session_state.get("cena_longa_ativa"):
                    resposta_final = cortar_antes_do_climax(resposta_final)

            except Exception as e:
                st.error(f"Erro: {e}")
                resposta_final = "[Erro ao gerar resposta]"

    salvar_interacao("assistant", resposta_final)
    st.session_state.session_msgs.append({"role": "assistant", "content": resposta_final})
    st.session_state.ultima_entrada_recebida = None



# --------------------------- #
# Reset de entrada ao clicar em imagem/v√≠deo
# --------------------------- #
def resetar_entrada():
    st.session_state.ultima_entrada_recebida = None

# Garantir chamada nos bot√µes
if st.session_state.get("mostrar_imagem") or st.session_state.get("mostrar_video"):
    resetar_entrada()





# --------------------------- #
# Interface
# --------------------------- #
st.title("üåπ Mary")
st.markdown("Conhe√ßa Mary, mas cuidado! Suas curvas s√£o perigosas...")

# Inicializa√ß√£o do hist√≥rico e resumo (sem mostrar o resumo aqui para n√£o duplicar)
if "base_history" not in st.session_state:
    try:
        st.session_state.base_history = carregar_ultimas_interacoes(n=15)
        aba_resumo = planilha.worksheet("perfil_mary")
        dados = aba_resumo.get_all_values()
        ultimo_resumo = "[Sem resumo dispon√≠vel]"
        for linha in reversed(dados[1:]):
            if len(linha) >= 7 and linha[6].strip():
                ultimo_resumo = linha[6].strip()
                break
        st.session_state.ultimo_resumo = ultimo_resumo
    except Exception as e:
        st.session_state.base_history = []
        st.session_state.ultimo_resumo = "[Erro ao carregar resumo]"
        st.warning(f"N√£o foi poss√≠vel carregar hist√≥rico ou resumo: {e}")

if "session_msgs" not in st.session_state:
    st.session_state.session_msgs = []

if "grande_amor" not in st.session_state:
    st.session_state.grande_amor = None

# --------------------------- #
# Bot√£o para excluir √∫ltima intera√ß√£o da planilha
# --------------------------- #
def excluir_ultimas_interacoes(aba_nome="interacoes_mary"):
    try:
        planilha = conectar_planilha()
        aba = planilha.worksheet(aba_nome)
        total_linhas = len(aba.get_all_values())

        if total_linhas <= 1:
            st.warning("Nenhuma intera√ß√£o para excluir.")
            return

        # Remove as duas √∫ltimas linhas (usu√°rio e resposta)
        aba.delete_rows(total_linhas - 1)
        aba.delete_rows(total_linhas - 2)

        st.success("üóëÔ∏è √öltima intera√ß√£o exclu√≠da da planilha com sucesso!")
    except Exception as e:
        st.error(f"Erro ao excluir intera√ß√£o: {e}")

# --------------------------- #
# Sidebar (vers√£o unificada, sem selectbox)
# --------------------------- #

with st.sidebar:
    st.title("üß† Configura√ß√µes de Mary")

    # üîÅ Remove a chave antiga se ainda existir
    if "escolha_desejo_sexual" in st.session_state:
        del st.session_state["escolha_desejo_sexual"]

    with st.expander("üíã Desejos de Mary (atalhos r√°pidos)", expanded=False):
        st.caption("Escolha um desejo para Mary expressar automaticamente.")

        desejos_mary = {
            "ü´¶ Chupar J√¢nio": "Mary se ajoelha lentamente, encarando J√¢nio com olhos famintos. ‚Äî Deixa eu cuidar de voc√™ do meu jeito... com a boca.",
            "üôà De quatro": "Mary se vira e se apoia nos cotovelos, empinando os quadris com um sorriso provocante. ‚Äî Assim‚Ä¶ do jeitinho que voc√™ gosta.",
            "üêé Cavalgar": "Mary monta em J√¢nio com ousadia, os cabelos caindo sobre os ombros. ‚Äî Agora voc√™ vai me sentir inteirinha‚Ä¶",
            "üå™Ô∏è Contra a parede": "Ela √© empurrada contra a parede, gemendo baixinho. ‚Äî Me domina... aqui mesmo.",
            "üõèÔ∏è Em cima da cama": "Mary se joga sobre os len√ß√≥is e abre espa√ßo. ‚Äî Vem‚Ä¶ aqui √© nosso palco agora.",
            "üöø No banho": "Com a √°gua escorrendo pelo corpo, Mary se aproxima molhada e nua. ‚Äî Quer brincar comigo aqui dentro?",
            "üöó No carro": "No banco de tr√°s do Porsche, Mary o puxa com for√ßa. ‚Äî Essa noite ningu√©m vai dirigir‚Ä¶ a n√£o ser meu desejo."
        }

        colunas = st.columns(2)
        for i, (emoji, frase) in enumerate(desejos_mary.items()):
            with colunas[i % 2]:
                if st.button(emoji):
                    st.session_state.session_msgs.append({
                        "role": "user",
                        "content": frase
                    })
                    st.success("‚ú® Desejo adicionado ao chat.")

modelos_disponiveis = {
    # === OPENROUTER ===
    "üí¨ DeepSeek V3 ‚òÖ‚òÖ‚òÖ‚òÖ ($)": "deepseek/deepseek-chat-v3-0324",
    "üß† DeepSeek R1 0528 ‚òÖ‚òÖ‚òÖ‚òÖ‚òÜ ($$)": "deepseek/deepseek-r1-0528",
    "üß† DeepSeek R1T2 Chimera ‚òÖ‚òÖ‚òÖ‚òÖ (free)": "tngtech/deepseek-r1t2-chimera:free",
    "üß† GPT-4.1 ‚òÖ‚òÖ‚òÖ‚òÖ‚òÖ (1M ctx)": "openai/gpt-4.1",
    "üëë WizardLM 8x22B ‚òÖ‚òÖ‚òÖ‚òÖ‚òÜ ($$$)": "microsoft/wizardlm-2-8x22b",
    "üëë Qwen 235B 2507 ‚òÖ‚òÖ‚òÖ‚òÖ‚òÖ (PAID)": "qwen/qwen3-235b-a22b-07-25",
    "üëë EVA Qwen2.5 72B ‚òÖ‚òÖ‚òÖ‚òÖ‚òÖ (RP Pro)": "eva-unit-01/eva-qwen-2.5-72b",
    "üëë EVA Llama 3.33 70B ‚òÖ‚òÖ‚òÖ‚òÖ‚òÖ (RP Pro)": "eva-unit-01/eva-llama-3.33-70b",
    "üé≠ Nous Hermes 2 Yi 34B ‚òÖ‚òÖ‚òÖ‚òÖ‚òÜ": "nousresearch/nous-hermes-2-yi-34b",
    "üî• MythoMax 13B ‚òÖ‚òÖ‚òÖ‚òÜ ($)": "gryphe/mythomax-l2-13b",
    "üíã LLaMA3 Lumimaid 8B ‚òÖ‚òÖ‚òÜ ($)": "neversleep/llama-3-lumimaid-8b",
    "üåπ Midnight Rose 70B ‚òÖ‚òÖ‚òÖ‚òÜ": "sophosympatheia/midnight-rose-70b",
    "üå∂Ô∏è Noromaid 20B ‚òÖ‚òÖ‚òÜ": "neversleep/noromaid-20b",
    "üíÄ Mythalion 13B ‚òÖ‚òÖ‚òÜ": "pygmalionai/mythalion-13b",
    "üêâ Anubis 70B ‚òÖ‚òÖ‚òÜ": "thedrummer/anubis-70b-v1.1",
    "üßö Rocinante 12B ‚òÖ‚òÖ‚òÜ": "thedrummer/rocinante-12b",
    "üç∑ Magnum v2 72B ‚òÖ‚òÖ‚òÜ": "anthracite-org/magnum-v2-72b",
    # === TOGETHER AI ===
    "üß† Qwen3 Coder 480B (Together)": "togethercomputer/Qwen3-Coder-480B-A35B-Instruct-FP8",
    "üëë Mixtral 8x7B v0.1 (Together)": "mistralai/Mixtral-8x7B-Instruct-v0.1"
}

modelo_selecionado = st.selectbox(
    "ü§ñ Modelo de IA",
    list(modelos_disponiveis.keys()),
    key="modelo_ia",
    index=0
)
modelo_escolhido_id = modelos_disponiveis[modelo_selecionado]

# üîπ Garante que o valor fique dispon√≠vel para todo o script
st.session_state["modelo_escolhido_id"] = modelo_escolhido_id

# ------------------------------- #
# üé≠ Emo√ß√£o Oculta de Mary
# ------------------------------- #
st.markdown("---")
st.subheader("üé≠ Emo√ß√£o Oculta de Mary")

emoes = ["nenhuma", "tristeza", "raiva", "felicidade", "tens√£o"]
escolhida = st.selectbox("Escolha a emo√ß√£o dominante:", emoes, index=0)

if st.button("Definir emo√ß√£o"):
    st.session_state.emocao_oculta = escolhida
    st.success(f"Mary agora est√° sentindo: {escolhida}")

# ------------------------------- #
# üé≤ Emo√ß√£o Aleat√≥ria
# ------------------------------- #
import random
if st.button("Sortear emo√ß√£o aleat√≥ria"):
    emocoes_possiveis = ["tristeza", "raiva", "felicidade", "tens√£o"]
    sorteada = random.choice(emocoes_possiveis)
    st.session_state.emocao_oculta = sorteada
    st.success(f"‚ú® Emo√ß√£o sorteada: {sorteada}")

# ------------------------------- #
# üé¨ Cena Longa no Sidebar
# ------------------------------- #
st.sidebar.markdown("---")
st.sidebar.subheader("üé¨ Cena Longa")

if st.sidebar.button("Ativar Cena Longa"):
    st.session_state.session_msgs = []
    st.session_state.memorias_usadas = set()
    st.session_state.contador_emocao = 0
    st.session_state["temperatura_forcada"] = 0.95
    st.session_state.emocao_oculta = "tens√£o"
    st.session_state["cena_longa_ativa"] = True
    st.sidebar.success("‚úÖ Mary poder√° ir at√© o fim da cena sem interrup√ß√µes.")

# ------------------------------- #
# üìù Cena Longa no Corpo Principal
# ------------------------------- #
st.markdown("---")
st.subheader("üìù Cena Longa Especial")

if st.button("Iniciar Cena Longa"):
    st.session_state.session_msgs = []
    st.session_state.memorias_usadas = set()
    st.session_state.contador_emocao = 0
    st.session_state["temperatura_forcada"] = 0.95
    st.session_state.emocao_oculta = "tens√£o"
    st.session_state["cena_longa_ativa"] = True

    st.success("‚ú® Cena Longa iniciada! Mary ter√° liberdade m√°xima na pr√≥xima resposta.")
    with st.chat_message("user"):
        st.markdown("_(Cena Longa ativada: Mary assume a narrativa com intensidade e profundidade emocional...)_")

# ------------------------------- #
# üéÆ V√≠deo e resumo
# ------------------------------- #
if st.button("üéÆ Ver v√≠deo atual"):
    st.video(f"https://github.com/welnecker/roleplay_imagens/raw/main/{fundo_video}")

if st.button("üìù Gerar resumo do cap√≠tulo"):
    try:
        cena_longa = st.session_state.get("cena_longa_ativa", False)
        n_resumo = 10 if cena_longa else 3
        ultimas = carregar_ultimas_interacoes(n=n_resumo)
        texto_resumo = "\n".join(f"{m['role']}: {m['content']}" for m in ultimas)

        prompt_resumo = (
            f"Resuma o seguinte trecho de conversa como um cap√≠tulo de novela, "
            f"mantendo o estilo narrativo e as emo√ß√µes presentes:\n\n{texto_resumo}\n\nResumo:"
        )

        response = requests.post(
            "https://openrouter.ai/api/v1/chat/completions",
            headers={
                "Authorization": f"Bearer {OPENROUTER_API_KEY}",
                "Content-Type": "application/json"
            },
            json={
                "model": "deepseek/deepseek-chat-v3-0324",
                "messages": [{"role": "user", "content": prompt_resumo}],
                "max_tokens": 900,
                "temperature": 0.9 if cena_longa else 0.85
            }
        )

        if response.status_code == 200:
            resumo_gerado = response.json()["choices"][0]["message"]["content"]
            salvar_resumo(resumo_gerado)
            st.session_state.ultimo_resumo = resumo_gerado
            st.success("‚úÖ Resumo colado na aba 'perfil_mary' com sucesso!")
            if cena_longa:
                st.info("üé¨ Resumo estendido gerado para a Cena Longa!")
            with st.expander("üìñ Ver resumo gerado"):
                st.markdown(f"```markdown\n{resumo_gerado}\n```")
        else:
            st.error("Erro ao gerar resumo automaticamente.")
    except Exception as e:
        st.error(f"Erro durante a gera√ß√£o do resumo: {e}")

# --------------------------- #
# üíò Grande amor
# --------------------------- #
st.markdown("---")
st.subheader("üíò Grande amor")
amor_input = st.text_input(
    "Nome do grande amor (deixe vazio se n√£o existe)",
    value=st.session_state.grande_amor or ""
)
if st.button("Definir grande amor"):
    st.session_state.grande_amor = amor_input.strip() or None
    if st.session_state.grande_amor:
        st.success(f"üíñ Agora Mary est√° apaixonada por {st.session_state.grande_amor}")
    else:
        st.info("Mary continua livre.")

# --------------------------- #
# ‚ûï Adicionar mem√≥ria fixa
# --------------------------- #
st.markdown("---")
st.subheader("‚ûï Adicionar mem√≥ria fixa")
nova_memoria = st.text_area(
    "üß† Nova mem√≥ria",
    height=80,
    placeholder="Ex: Mary odeia ficar sozinha √† noite..."
)
if st.button("üíæ Salvar mem√≥ria"):
    if nova_memoria.strip():
        salvar_memoria(nova_memoria)
    else:
        st.warning("Digite algo antes de salvar.")

# --------------------------- #
# üóëÔ∏è Excluir √∫ltima intera√ß√£o
# --------------------------- #
if st.button("üóëÔ∏è Excluir √∫ltima intera√ß√£o da planilha"):
    excluir_ultimas_interacoes("interacoes_mary")




    # --------------------------- #
    # Mem√≥rias com filtro de busca
    # --------------------------- #
    st.markdown("---")
    st.subheader("üíæ Mem√≥rias (busca)")
    try:
        aba_memorias = planilha.worksheet("memorias")
        dados_mem = aba_memorias.col_values(1)
        busca = st.text_input("üîç Buscar mem√≥ria...", key="filtro_memoria").strip().lower()
        filtradas = [m for m in dados_mem if busca in m.lower()] if busca else dados_mem
        st.caption(f"{len(filtradas)} mem√≥rias encontradas")
        st.markdown("\n".join(f"* {m}" for m in filtradas if m.strip()))
    except Exception as e:
        st.error(f"Erro ao carregar mem√≥rias: {e}")

    # --------------------------- #
    # Fragmentos Ativos
    # --------------------------- #
    if st.session_state.get("session_msgs"):
        ultima_msg = st.session_state.session_msgs[-1].get("content", "")
        fragmentos = carregar_fragmentos()
        fragmentos_ativos = buscar_fragmentos_relevantes(ultima_msg, fragmentos)
        if fragmentos_ativos:
            st.subheader("üìö Fragmentos Ativos")
            for f in fragmentos_ativos:
                st.markdown(f"- {f['texto']}")



# --------------------------- #
# Hist√≥rico
# --------------------------- #
historico_total = st.session_state.base_history + st.session_state.session_msgs
for m in historico_total:
    with st.chat_message(m["role"]):
        st.markdown(m["content"])

# Exibe o resumo **uma √∫nica vez**, no final
if st.session_state.get("ultimo_resumo"):
    with st.chat_message("assistant"):
        st.markdown(f"### üß† *Cap√≠tulo anterior...*\n\n> {st.session_state.ultimo_resumo}")

# --------------------------- #
# Fun√ß√£o de resposta (OpenRouter + Together)
# --------------------------- #
def responder_com_modelo_escolhido():
    modelo = st.session_state.get("modelo_escolhido_id", "deepseek/deepseek-chat-v3-0324")

    # Detecta provedor com base no ID do modelo
    if modelo.startswith("togethercomputer/") or modelo.startswith("mistralai/"):
        st.session_state["provedor_ia"] = "together"
        return gerar_resposta_together_stream(modelo)
    else:
        st.session_state["provedor_ia"] = "openrouter"
        return gerar_resposta_openrouter_stream(modelo)


# ---------------------------
# üåô Efeitos Sensorial-Narrativos por Emo√ß√£o Oculta (sem termos t√©cnicos)
# ---------------------------
CINEMATIC_EFFECTS = {
    "tristeza": [
        "O sil√™ncio ao redor pesa, como se o mundo estivesse longe.",
        "O ar parece mais frio, e cada gesto carrega hesita√ß√£o.",
        "As sombras parecem se alongar ao redor, como se absorvessem as palavras n√£o ditas."
    ],
    "raiva": [
        "O peito dela sobe e desce com for√ßa, cada respira√ß√£o carregada de tens√£o.",
        "As palavras v√™m r√°pidas, como se o controle estivesse por um fio.",
        "Tudo parece mais intenso ‚Äî os sons, os olhares, at√© o calor na pele."
    ],
    "felicidade": [
        "O riso dela ecoa como m√∫sica, espont√¢neo e contagiante.",
        "A luz entra suave, como se o dia fosse feito s√≥ para aquele momento.",
        "Tudo ao redor parece vivo ‚Äî os cheiros, as cores, os gestos pequenos."
    ],
    "tens√£o": [
        "O olhar dela busca respostas, como se o tempo tivesse desacelerado.",
        "Cada movimento √© mais contido, como se o ar estivesse suspenso.",
        "O toque que n√£o acontece diz mais que mil palavras."
    ],
    "nenhuma": [
        "O ambiente permanece neutro, sem nada de especial chamando aten√ß√£o.",
        "Mary age de forma serena, guiada apenas pelo que sente no momento.",
        "Tudo parece comum, mas ainda assim... cheio de possibilidades."
    ]
}
 


# --------------------------- #
# Entrada do usu√°rio (sem termos t√©cnicos no output da IA)
# --------------------------- #
entrada_raw = st.chat_input("Digite sua mensagem para Mary... (use '*' ou '@Mary:')")

if entrada_raw:
    entrada_raw = entrada_raw.strip()
    estado_amor = st.session_state.get("grande_amor")
    st.session_state.memorias_usadas = set()

    if "emocao_oculta" not in st.session_state:
        st.session_state.emocao_oculta = None
    if "climax_autorizado" not in st.session_state:
        st.session_state.climax_autorizado = False

    # üîç Detecta se o usu√°rio autorizou cl√≠max
    frases_autorizacao = [
        "vou gozar", "estou gozando", "goza comigo",
        "quero gozar", "gozando", "vem comigo"
    ]
    respostas_rapidas = ["sim", "quero", "vai", "continua", "pode"]

    entrada_lower = entrada_raw.lower()
    if any(frase in entrada_lower for frase in frases_autorizacao) or entrada_lower in respostas_rapidas:
        st.session_state.climax_autorizado = True
        st.success("üîì Cl√≠max autorizado pelo usu√°rio!")

    # Caso 1: Comando de roteirista com @Mary:
    if entrada_raw.lower().startswith("@mary:"):
        comando = entrada_raw[len("@mary:"):].strip()

        # Define emo√ß√£o oculta automaticamente com base no comando
        if any(x in comando.lower() for x in ["triste", "sozinha", "choro", "saudade"]):
            st.session_state.emocao_oculta = "tristeza"
        elif any(x in comando.lower() for x in ["raiva", "ci√∫me", "√≥dio", "furiosa"]):
            st.session_state.emocao_oculta = "raiva"
        elif any(x in comando.lower() for x in ["feliz", "alegre", "orgulhosa", "leve"]):
            st.session_state.emocao_oculta = "felicidade"
        elif any(x in comando.lower() for x in ["desejo", "provoca√ß√£o", "tens√£o", "calor"]):
            st.session_state.emocao_oculta = "tens√£o"
        else:
            st.session_state.emocao_oculta = "nenhuma"

        # Fragmentos e mem√≥rias
        fragmentos = carregar_fragmentos()
        mem = carregar_memorias()
        fragmentos_ativos = buscar_fragmentos_relevantes(comando, fragmentos)

        contexto_memoria = ""
        if fragmentos_ativos:
            contexto_memoria += "\n" + "\n".join(f"- {f['texto']}" for f in fragmentos_ativos)
        if mem:
            contexto_memoria += "\n" + mem["content"]

        entrada = f"""
[CENA_AUT√îNOMA]
Mary inicia a cena com base neste comando: {comando}

Ela deve agir com naturalidade, sem usar termos t√©cnicos ou efeitos sonoros.
Use narra√ß√£o em 3¬™ pessoa e falas/pensamentos em 1¬™.
Adapte o tom conforme a emo√ß√£o oculta: {st.session_state.emocao_oculta or "nenhuma"}.

{contexto_memoria.strip()}
""".strip()
        entrada_visivel = entrada_raw

    # Caso 2: Apenas "*"
    elif entrada_raw == "*":
        entrada = (
            f"[CONTINUAR_CENA] Continue a cena anterior com naturalidade.\n"
            f"Evite termos t√©cnicos. Emo√ß√£o oculta: {st.session_state.emocao_oculta or 'nenhuma'}"
        )
        entrada_visivel = "*"

    # Caso 3: "* algo"
    elif entrada_raw.startswith("* ") and not entrada_raw.lower().startswith("* desejo:"):
        extra = entrada_raw[2:].strip()
        entrada = (
            f"[CONTINUAR_CENA] Continue a cena anterior de forma fluida e coerente.\n"
            f"Evite termos t√©cnicos. Emo√ß√£o oculta: {st.session_state.emocao_oculta or 'nenhuma'}\n"
            f"Inclua: {extra}"
        )
        entrada_visivel = entrada_raw

    # Caso 4: "* Desejo: ..."
    elif entrada_raw.lower().startswith("* desejo:"):
        desejo = entrada_raw[9:].strip()
        entrada = (
            f"[AVALIAR_DESEJO] O usu√°rio expressou o desejo: '{desejo}'.\n"
            "Analise com naturalidade e sensibilidade se esse desejo faz sentido no momento da cena, considerando:\n"
            "- a situa√ß√£o atual\n"
            "- a emo√ß√£o de Mary\n"
            "- o n√≠vel de confian√ßa com o usu√°rio\n\n"
            "‚ö†Ô∏è Se o desejo for incoerente, Mary n√£o deve corresponder. Ela pode mudar de assunto, impor limites com leveza ou brincar.\n"
            "‚ö†Ô∏è Se o desejo for coerente, Mary pode reagir emocionalmente ‚Äî mas com naturalidade e sem teatralidade."
        )
        entrada_visivel = entrada_raw

    # Caso 5: Entrada comum
    else:
        entrada = entrada_raw
        entrada_visivel = entrada_raw

    # --------------------------- #
    # Exibir no chat e registrar
    # --------------------------- #
    st.chat_message("user").markdown(entrada_visivel)
    salvar_interacao("user", entrada_visivel)
    st.session_state.session_msgs.append({"role": "user", "content": entrada})
    st.session_state.ultima_entrada_recebida = entrada

    with st.chat_message("assistant"):
        placeholder = st.empty()
        with st.spinner("Mary est√° atuando na cena..."):
            try:
                resposta_final = responder_com_modelo_escolhido()

                # ‚ö†Ô∏è Prote√ß√£o contra cl√≠max t√©cnico, apenas se n√£o for autorizado
                climas_proibidos = ["gozar", "cl√≠max"]
                if not st.session_state.get("climax_autorizado", False) and any(p in resposta_final.lower() for p in climas_proibidos):
                    resposta_final = cortar_antes_do_climax(resposta_final)

            except Exception as e:
                st.error(f"Erro: {e}")
                resposta_final = "[Erro ao gerar resposta]"

    salvar_interacao("assistant", resposta_final)
    st.session_state.session_msgs.append({"role": "assistant", "content": resposta_final})

    # --------------------------- #
    # Valida√ß√£o sem√¢ntica
    # --------------------------- #
    if len(st.session_state.session_msgs) >= 2:
        texto_anterior = st.session_state.session_msgs[-2]["content"]
        texto_atual = st.session_state.session_msgs[-1]["content"]
        alerta_semantica = verificar_quebra_semantica_openai(texto_anterior, texto_atual)
        if alerta_semantica:
            st.info(alerta_semantica)





def converter_link_drive(link, tipo="imagem"):
    """
    Converte link do Google Drive para visualiza√ß√£o no Streamlit.
    - tipo="imagem": retorna uc?export=view&id=...
    - tipo="video": retorna .../preview
    """
    match = re.search(r'/d/([a-zA-Z0-9_-]+)', link)
    if not match:
        match = re.search(r'id=([a-zA-Z0-9_-]+)', link)
    if match:
        file_id = match.group(1)
        if tipo == "video":
            return f"https://drive.google.com/file/d/{file_id}/preview"
        else:
            return f"https://drive.google.com/uc?export=view&id={file_id}"
    return link


# --------------------------- #
# Carregar v√≠deos e imagens da aba "video_imagem"
# --------------------------- #
def carregar_midia_disponivel():
    try:
        aba_midia = planilha.worksheet("video_imagem")
        dados = aba_midia.get_all_values()
        midias = []
        for linha in dados:
            if not linha:
                continue
            video_link = linha[0].strip() if len(linha) > 0 else ""
            imagem_link = linha[1].strip() if len(linha) > 1 else ""
            if video_link or imagem_link:
                midias.append({"video": video_link, "imagem": imagem_link})
        return midias
    except Exception as e:
        st.error(f"Erro ao carregar m√≠dia: {e}")
        return []



midia_disponivel = carregar_midia_disponivel()
videos = [m["video"] for m in midia_disponivel if m["video"]]
imagens = [m["imagem"] for m in midia_disponivel if m["imagem"]]

# --------------------------- #
# Inicializar √≠ndices, se n√£o existirem
# --------------------------- #
if "video_idx" not in st.session_state:
    st.session_state.video_idx = 0
if "img_idx" not in st.session_state:
    st.session_state.img_idx = 0

# --------------------------- #
# Bot√µes de controle
# --------------------------- #
st.divider()
st.subheader("üí° Surpreender Mary")

col1, col2, col3 = st.columns([1, 1, 2])

with col1:
    if st.button("üé• V√≠deo Surpresa") and videos:
        st.session_state.video_idx = (st.session_state.video_idx + 1) % len(videos)
        st.session_state.mostrar_video = videos[st.session_state.video_idx]
        st.session_state.mostrar_imagem = None
        st.session_state.ultima_entrada_recebida = None

with col2:
    if st.button("üñºÔ∏è Imagem Surpresa") and imagens:
        st.session_state.img_idx = (st.session_state.img_idx + 1) % len(imagens)
        st.session_state.mostrar_imagem = imagens[st.session_state.img_idx]
        st.session_state.mostrar_video = None
        st.session_state.ultima_entrada_recebida = None

with col3:
    if st.button("‚ùå Fechar"):
        st.session_state.mostrar_video = None
        st.session_state.mostrar_imagem = None
        st.success("M√≠dia fechada.")

# --------------------------- #
# Exibi√ß√£o da m√≠dia
# --------------------------- #

# Imagem
if st.session_state.get("mostrar_imagem"):
    imagem = st.session_state.mostrar_imagem
    if imagem and isinstance(imagem, str) and imagem.strip():
        largura = st.slider("üìê Ajustar largura da imagem", 200, 1200, 640, step=50)
        try:
            st.image(imagem, width=largura)
        except Exception:
            st.warning("Erro ao carregar a imagem selecionada.")
    else:
        st.warning("N√£o h√° mais imagens dispon√≠veis para exibir.")

# V√≠deo
if st.session_state.get("mostrar_video"):
    video = st.session_state.mostrar_video
    if video and isinstance(video, str) and video.strip():
        try:
            st.video(video)
        except Exception:
            st.warning("Erro ao carregar o v√≠deo selecionado.")
    else:
        st.warning("N√£o h√° mais v√≠deos dispon√≠veis para exibir.")
